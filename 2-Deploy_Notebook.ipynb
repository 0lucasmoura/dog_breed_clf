{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for deploying and evaluate model on aws\n",
    "\n",
    "On this notebook we will be training and evaluating a dog breed classifier based on feature extraction of a resnet50 archtecture!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import aws sagemaker apis\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# default S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-031843945636/dog-breed-data\n"
     ]
    }
   ],
   "source": [
    "# specify where to upload in S3\n",
    "data_dir = './data/dataset/'\n",
    "prefix = 'dog-breed-data'\n",
    "\n",
    "s3_keys = [obj.key for obj in boto3.resource('s3').Bucket(bucket).objects.all()]\n",
    "# upload to S3 - Due to the size of the dataset it takes some time to finish...\n",
    "if any(prefix in s for s in s3_keys):\n",
    "    input_data = f\"s3://{bucket}/{prefix}\"\n",
    "else:\n",
    "    input_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the pytorch estimator for the problem. It's this api that will handle all the load of creating the training job and deploy.\n",
    "\n",
    "It's needed to specify the train script on it though. the pytorch framework version, train_instance_type and model hyperparameters are really important atributes of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a PyTorch wrapper\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# specify an output path\n",
    "# prefix is specified above\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    source_dir='source', # this should be just \"source\" for your code\n",
    "                    role=role,\n",
    "                    framework_version='1.5.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.p2.xlarge',\n",
    "                    output_path=output_path,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    hyperparameters={\n",
    "                        'output_dim': 120,\n",
    "                        'hidden_dim': 1000,\n",
    "                        'epochs': 20, # could change to higher\n",
    "                        'batch-size': 32,\n",
    "                        'lr': 0.01\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we start the training job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-22 01:41:23 Starting - Starting the training job...\n",
      "2020-05-22 01:41:25 Starting - Launching requested ML instances.........\n",
      "2020-05-22 01:43:06 Starting - Preparing the instances for training.........\n",
      "2020-05-22 01:44:24 Downloading - Downloading input data..................\n",
      "2020-05-22 01:47:33 Training - Downloading the training image..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-05-22 01:48:01,182 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-05-22 01:48:01,209 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-05-22 01:48:04,363 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-05-22 01:48:04,723 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-05-22 01:48:04,724 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-05-22 01:48:04,724 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-05-22 01:48:04,724 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmptvwqdpb1/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\n",
      "  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=13306 sha256=20a2eaa01657a725f29305ba4ced4f861314ea6fa516278bbacef9bd7770135b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7y56gh68/wheels/43/f7/03/b373be663e478ec71a4f4e908906f9dae077d106f5f39cb4cd\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-05-22 01:48:07,533 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 32,\n",
      "        \"hidden_dim\": 1000,\n",
      "        \"lr\": 0.01,\n",
      "        \"epochs\": 20,\n",
      "        \"output_dim\": 120\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-05-22-01-41-22-650\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-031843945636/pytorch-training-2020-05-22-01-41-22-650/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":32,\"epochs\":20,\"hidden_dim\":1000,\"lr\":0.01,\"output_dim\":120}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-031843945636/pytorch-training-2020-05-22-01-41-22-650/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":32,\"epochs\":20,\"hidden_dim\":1000,\"lr\":0.01,\"output_dim\":120},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-05-22-01-41-22-650\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-031843945636/pytorch-training-2020-05-22-01-41-22-650/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"32\",\"--epochs\",\"20\",\"--hidden_dim\",\"1000\",\"--lr\",\"0.01\",\"--output_dim\",\"120\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=1000\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.01\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIM=120\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --batch-size 32 --epochs 20 --hidden_dim 1000 --lr 0.01 --output_dim 120\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "2020-05-22 01:48:00 Training - Training image download completed. Training in progress.\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mEpoch 0/19\u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34m[2020-05-22 01:48:17.688 algo-1:43 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-05-22 01:48:17.689 algo-1:43 INFO hook.py:183] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-05-22 01:48:17.689 algo-1:43 INFO hook.py:228] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-05-22 01:48:17.714 algo-1:43 INFO hook.py:364] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2020-05-22 01:48:17.714 algo-1:43 INFO hook.py:422] Hook is writing from the hook with pid: 43\n",
      "\u001b[0m\n",
      "\u001b[34mtrain Loss: 4.6347 Acc: 0.4881\u001b[0m\n",
      "\u001b[34mval Loss: 3.9365 Acc: 0.6285\u001b[0m\n",
      "\u001b[34mEpoch 1/19\u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34mtrain Loss: 3.9047 Acc: 0.6282\u001b[0m\n",
      "\u001b[34mval Loss: 3.0211 Acc: 0.7406\u001b[0m\n",
      "\u001b[34mEpoch 2/19\u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34mtrain Loss: 3.8099 Acc: 0.6729\u001b[0m\n",
      "\u001b[34mval Loss: 3.2891 Acc: 0.7496\u001b[0m\n",
      "\u001b[34mEpoch 3/19\u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34mtrain Loss: 3.7040 Acc: 0.7067\u001b[0m\n",
      "\u001b[34mval Loss: 4.1237 Acc: 0.7191\u001b[0m\n",
      "\u001b[34mEpoch 4/19\u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34mtrain Loss: 3.7417 Acc: 0.7165\u001b[0m\n",
      "\u001b[34mval Loss: 3.9454 Acc: 0.7463\u001b[0m\n",
      "\u001b[34mEpoch 5/19\u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34mtrain Loss: 3.8046 Acc: 0.7271\u001b[0m\n",
      "\u001b[34mval Loss: 4.4694 Acc: 0.7452\u001b[0m\n",
      "\u001b[34mEpoch 6/19\u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34mtrain Loss: 3.6499 Acc: 0.7403\u001b[0m\n",
      "\u001b[34mval Loss: 4.1822 Acc: 0.7526\u001b[0m\n",
      "\u001b[34mEpoch 7/19\u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34mtrain Loss: 3.7905 Acc: 0.7460\u001b[0m\n",
      "\u001b[34mval Loss: 4.1200 Acc: 0.7663\u001b[0m\n",
      "\u001b[34mEpoch 8/19\u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34mtrain Loss: 3.7205 Acc: 0.7546\u001b[0m\n",
      "\u001b[34mval Loss: 4.4478 Acc: 0.7570\u001b[0m\n",
      "\u001b[34mEpoch 9/19\u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34mtrain Loss: 3.5875 Acc: 0.7646\u001b[0m\n",
      "\u001b[34mval Loss: 4.6424 Acc: 0.7709\u001b[0m\n",
      "\u001b[34mEpoch 10/19\u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34mtrain Loss: 3.7460 Acc: 0.7707\u001b[0m\n",
      "\u001b[34mval Loss: 4.9996 Acc: 0.7610\u001b[0m\n",
      "\u001b[34mEpoch 11/19\u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34mtrain Loss: 3.6716 Acc: 0.7781\u001b[0m\n",
      "\u001b[34mval Loss: 4.7383 Acc: 0.7749\u001b[0m\n",
      "\u001b[34mEpoch 12/19\u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34mtrain Loss: 3.7308 Acc: 0.7743\u001b[0m\n",
      "\u001b[34mval Loss: 5.3937 Acc: 0.7522\u001b[0m\n",
      "\u001b[34mEpoch 13/19\u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34mtrain Loss: 3.6303 Acc: 0.7884\u001b[0m\n",
      "\u001b[34mval Loss: 5.0189 Acc: 0.7764\u001b[0m\n",
      "\u001b[34mEpoch 14/19\u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34mtrain Loss: 3.5583 Acc: 0.7863\u001b[0m\n",
      "\u001b[34mval Loss: 5.0300 Acc: 0.7766\u001b[0m\n",
      "\u001b[34mEpoch 15/19\u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34mtrain Loss: 3.6761 Acc: 0.7876\u001b[0m\n",
      "\u001b[34mval Loss: 5.2696 Acc: 0.7730\u001b[0m\n",
      "\u001b[34mEpoch 16/19\u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34mtrain Loss: 3.5267 Acc: 0.7964\u001b[0m\n",
      "\u001b[34mval Loss: 5.0509 Acc: 0.7820\u001b[0m\n",
      "\u001b[34mEpoch 17/19\u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34mtrain Loss: 3.3794 Acc: 0.7999\u001b[0m\n",
      "\u001b[34mval Loss: 5.1563 Acc: 0.7787\u001b[0m\n",
      "\u001b[34mEpoch 18/19\u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34mtrain Loss: 3.5866 Acc: 0.7979\u001b[0m\n",
      "\u001b[34mval Loss: 5.2950 Acc: 0.7783\u001b[0m\n",
      "\u001b[34mEpoch 19/19\u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34mtrain Loss: 3.4717 Acc: 0.8086\u001b[0m\n",
      "\n",
      "2020-05-22 02:36:02 Uploading - Uploading generated training model\u001b[34mval Loss: 6.1144 Acc: 0.7677\u001b[0m\n",
      "\u001b[34mTraining complete in 47m 44s\u001b[0m\n",
      "\u001b[34mBest val Acc: 0.781971\u001b[0m\n",
      "\u001b[34m[2020-05-22 02:36:00.184 algo-1:43 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-05-22 02:36:00,873 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-05-22 02:36:19 Completed - Training job completed\n",
      "Training seconds: 3115\n",
      "Billable seconds: 3115\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train': os.path.join(input_data, 'train'), 'test': os.path.join(input_data, 'test')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying the model for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.utils import get_validation_dataset\n",
    "\n",
    "dataset = get_validation_dataset('data/dataset/val/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_label = dataset.targets\n",
    "predicted_labels = [np.argmax(predictor.predict(data.unsqueeze(0)), 1)[0] for data, label in dataset] # takes some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "metrics = {key: precision_recall_fscore_support(actual_label, predicted_labels, average=key) for key in [\"micro\", \"macro\", \"weighted\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.777\n",
      "Model metrics: \n",
      " (micro)   precision - 0.777, recall - 0.777, f1score - 0.777\n",
      " (macro)   precision - 0.808, recall - 0.777, f1score - 0.764\n",
      "(weighted) precision - 0.826, recall - 0.777, f1score - 0.775\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model accuracy: {accuracy_score(actual_label, predicted_labels):.3f}\")\n",
    "print(f'Model metrics: \\n'\n",
    "      f\" (micro)   precision - {metrics['micro'][0]:.3f}, recall - {metrics['micro'][1]:.3f}, f1score - {metrics['micro'][2]:.3f}\\n\"\n",
    "      f\" (macro)   precision - {metrics['macro'][0]:.3f}, recall - {metrics['macro'][1]:.3f}, f1score - {metrics['macro'][2]:.3f}\\n\"\n",
    "      f\"(weighted) precision - {metrics['weighted'][0]:.3f}, recall - {metrics['weighted'][1]:.3f}, f1score - {metrics['weighted'][2]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
